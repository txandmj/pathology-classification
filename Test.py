import torch
from torch.utils.data import DataLoader
from sklearn.model_selection import StratifiedKFold
from TrainModel import get_conservative_transforms, train_conservative_model
from PathologyDataset import DiagnosticPathologyDataset
from Model import ConservativeModel
import numpy as np
import cv2
import os
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')


def data_leakage_check(image_paths, labels, fold_splits):
    """æ£€æŸ¥æ•°æ®æ³„æ¼"""

    print("\nğŸ” Data Leakage Check:")
    print("=" * 40)

    for fold_idx, (train_idx, val_idx) in enumerate(fold_splits):
        train_paths = [image_paths[i] for i in train_idx]
        val_paths = [image_paths[i] for i in val_idx]

        # æ£€æŸ¥æ–‡ä»¶åé‡å 
        train_names = set([os.path.basename(p) for p in train_paths])
        val_names = set([os.path.basename(p) for p in val_paths])
        overlap = train_names.intersection(val_names)

        print(f"Fold {fold_idx + 1}:")
        print(f"  Train images: {len(train_paths)}")
        print(f"  Val images: {len(val_paths)}")
        print(f"  Filename overlap: {len(overlap)} {'âŒ' if overlap else 'âœ…'}")

        if overlap:
            print(f"    Overlapping files: {list(overlap)[:5]}...")  # æ˜¾ç¤ºå‰5ä¸ª

        # æ£€æŸ¥ç±»åˆ«åˆ†å¸ƒ
        train_labels = [labels[i] for i in train_idx]
        val_labels = [labels[i] for i in val_idx]

        print(f"  Train LNM/non-LNM: {sum(train_labels)}/{len(train_labels) - sum(train_labels)}")
        print(f"  Val LNM/non-LNM: {sum(val_labels)}/{len(val_labels) - sum(val_labels)}")

        # æ£€æŸ¥æç«¯ä¸å¹³è¡¡
        if sum(val_labels) == 0 or sum(val_labels) == len(val_labels):
            print(f"  âš ï¸  WARNING: Validation set has only one class!")


def diagnostic_cross_validate(image_paths, labels, n_splits=5):
    """è¯Šæ–­æ€§äº¤å‰éªŒè¯"""

    # é¦–å…ˆè¿›è¡Œæ•°æ®æ³„æ¼æ£€æŸ¥
    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    fold_splits = list(skf.split(image_paths, labels))
    data_leakage_check(image_paths, labels, fold_splits)

    cv_results = []
    detailed_results = []

    train_transform, val_transform = get_conservative_transforms()

    for fold, (train_idx, val_idx) in enumerate(fold_splits):
        print(f'\n{"=" * 25} Fold {fold + 1}/{n_splits} {"=" * 25}')

        # åˆ’åˆ†æ•°æ®
        train_paths = [image_paths[i] for i in train_idx]
        train_labels = [labels[i] for i in train_idx]
        val_paths = [image_paths[i] for i in val_idx]
        val_labels = [labels[i] for i in val_idx]

        # æ£€æŸ¥ç±»åˆ«åˆ†å¸ƒ
        train_lnm = sum(train_labels)
        val_lnm = sum(val_labels)
        print(f'Train: {len(train_paths)} images ({train_lnm} LNM, {len(train_labels) - train_lnm} non-LNM)')
        print(f'Val: {len(val_paths)} images ({val_lnm} LNM, {len(val_labels) - val_lnm} non-LNM)')

        # å¦‚æœéªŒè¯é›†ç±»åˆ«ä¸å¹³è¡¡ï¼Œè·³è¿‡æ­¤fold
        if val_lnm == 0 or val_lnm == len(val_labels):
            print("âŒ Skipping fold due to single-class validation set")
            continue

        # åˆ›å»ºæ•°æ®é›†ï¼ˆå‡å°‘patchæ•°é‡ï¼‰
        train_dataset = DiagnosticPathologyDataset(
            train_paths, train_labels, train_transform,
            patch_size=224, patches_per_image=2, seed=42 + fold  # æ¯ä¸ªfoldä¸åŒçš„ç§å­
        )
        val_dataset = DiagnosticPathologyDataset(
            val_paths, val_labels, val_transform,
            patch_size=224, patches_per_image=1, seed=42 + fold  # éªŒè¯æ—¶åªç”¨1ä¸ªpatch
        )

        # å°batch size
        train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True,
                                  num_workers=0, drop_last=True)  # é¿å…å¤šè¿›ç¨‹é—®é¢˜
        val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False,
                                num_workers=0)

        # åˆ›å»ºä¿å®ˆæ¨¡å‹
        model = ConservativeModel(num_classes=2, dropout_rate=0.7)

        # è®­ç»ƒ
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f'Using device: {device}')

        model, history = train_conservative_model(model, train_loader, val_loader,
                                                  num_epochs=15, device=device)

        # è¯„ä¼°
        best_auc = max(history['val_auc']) if history['val_auc'] else 0.5
        cv_results.append(best_auc)

        # è¯¦ç»†ç»“æœ
        fold_result = {
            'fold': fold + 1,
            'best_auc': best_auc,
            'final_train_loss': history['train_loss'][-1] if history['train_loss'] else 0,
            'final_val_loss': history['val_loss'][-1] if history['val_loss'] else 0,
            'overfitting_gap': history['val_loss'][-1] - history['train_loss'][-1] if history['val_loss'] and history[
                'train_loss'] else 0,
            'train_size': len(train_dataset),
            'val_size': len(val_dataset)
        }
        detailed_results.append(fold_result)

        print(f'Fold {fold + 1} Results:')
        print(f'  Best AUC: {best_auc:.4f}')
        print(f'  Overfitting gap: {fold_result["overfitting_gap"]:.4f}')

        # ç»˜åˆ¶æ­¤foldçš„è®­ç»ƒæ›²çº¿
        if history['val_auc']:
            plot_fold_analysis(history, fold_result, fold)

    return cv_results, detailed_results


def plot_fold_analysis(history, fold_result, fold_num):
    """ç»˜åˆ¶å•ä¸ªfoldçš„è¯¦ç»†åˆ†æ"""

    fig, axes = plt.subplots(2, 3, figsize=(15, 8))

    # æŸå¤±æ›²çº¿
    axes[0, 0].plot(history['train_loss'], 'b-', label='Train', linewidth=2)
    axes[0, 0].plot(history['val_loss'], 'r-', label='Validation', linewidth=2)
    axes[0, 0].set_title('Loss Curves')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Loss')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)

    # AUCæ›²çº¿
    axes[0, 1].plot(history['val_auc'], 'g-', linewidth=2)
    axes[0, 1].axhline(y=1.0, color='r', linestyle='--', alpha=0.7, label='Perfect AUC')
    axes[0, 1].axhline(y=0.8, color='orange', linestyle='--', alpha=0.7, label='Clinical Threshold')
    axes[0, 1].set_title('Validation AUC')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('AUC')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)
    axes[0, 1].set_ylim(0.4, 1.05)

    # è¿‡æ‹Ÿåˆåˆ†æ
    overfitting_gap = np.array(history['val_loss']) - np.array(history['train_loss'])
    axes[0, 2].plot(overfitting_gap, 'purple', linewidth=2)
    axes[0, 2].axhline(y=0, color='k', linestyle='-', alpha=0.3)
    axes[0, 2].axhline(y=0.1, color='orange', linestyle='--', alpha=0.7, label='Warning Threshold')
    axes[0, 2].set_title('Overfitting Gap')
    axes[0, 2].set_xlabel('Epoch')
    axes[0, 2].set_ylabel('Val Loss - Train Loss')
    axes[0, 2].legend()
    axes[0, 2].grid(True, alpha=0.3)

    # å‡†ç¡®ç‡å¯¹æ¯”
    axes[1, 0].plot(history['train_acc'], 'b-', label='Train', linewidth=2)
    axes[1, 0].plot(history['val_acc'], 'r-', label='Validation', linewidth=2)
    axes[1, 0].set_title('Accuracy Curves')
    axes[1, 0].set_xlabel('Epoch')
    axes[1, 0].set_ylabel('Accuracy (%)')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)

    # æœ€ç»ˆæŒ‡æ ‡æ€»ç»“
    axes[1, 1].axis('off')
    summary_text = f"""
Fold {fold_num + 1} Summary:

Best AUC: {fold_result['best_auc']:.4f}
Final Train Loss: {fold_result['final_train_loss']:.4f}
Final Val Loss: {fold_result['final_val_loss']:.4f}
Overfitting Gap: {fold_result['overfitting_gap']:.4f}

Dataset Sizes:
Train Patches: {fold_result['train_size']}
Val Patches: {fold_result['val_size']}

Health Check:
{'âœ… Healthy' if fold_result['overfitting_gap'] < 0.1 and fold_result['best_auc'] < 0.98 else 'âš ï¸  Needs Attention'}
    """
    axes[1, 1].text(0.1, 0.5, summary_text, fontsize=10, verticalalignment='center',
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgray", alpha=0.5))

    # ç¨³å®šæ€§åˆ†æ
    if len(history['val_auc']) > 5:
        last_5_auc = history['val_auc'][-5:]
        auc_std = np.std(last_5_auc)
        axes[1, 2].plot(range(len(history['val_auc'])), history['val_auc'], 'g-', alpha=0.7)
        axes[1, 2].plot(range(len(history['val_auc']) - 5, len(history['val_auc'])),
                        last_5_auc, 'r-', linewidth=3, label=f'Last 5 epochs (std={auc_std:.3f})')
        axes[1, 2].set_title('AUC Stability')
        axes[1, 2].set_xlabel('Epoch')
        axes[1, 2].set_ylabel('AUC')
        axes[1, 2].legend()
        axes[1, 2].grid(True, alpha=0.3)

    plt.suptitle(f'Diagnostic Analysis - Fold {fold_num + 1}', fontsize=14)
    plt.tight_layout()
    plt.savefig(f'diagnostic_fold_{fold_num + 1}.png', dpi=150, bbox_inches='tight')
    plt.show()


def final_diagnostic_report(cv_results, detailed_results):
    """ç”Ÿæˆæœ€ç»ˆè¯Šæ–­æŠ¥å‘Š"""

    print('\n' + '=' * 70)
    print('ğŸ“‹ FINAL DIAGNOSTIC REPORT')
    print('=' * 70)

    if not cv_results:
        print("âŒ No valid results obtained!")
        return

    mean_auc = np.mean(cv_results)
    std_auc = np.std(cv_results)

    print(f'\nğŸ“Š Performance Summary:')
    print(f'  Folds completed: {len(cv_results)}/5')
    print(f'  Mean AUC: {mean_auc:.4f} Â± {std_auc:.4f}')
    print(f'  Min AUC: {min(cv_results):.4f}')
    print(f'  Max AUC: {max(cv_results):.4f}')

    # ç¨³å®šæ€§åˆ†æ
    auc_range = max(cv_results) - min(cv_results)
    print(f'\nğŸ¯ Stability Analysis:')
    print(f'  AUC Range: {auc_range:.4f}')

    if auc_range > 0.2:
        print(f'  âš ï¸  HIGH INSTABILITY: Results vary significantly across folds')
    elif auc_range > 0.1:
        print(f'  âš ï¸  MODERATE INSTABILITY: Some variation across folds')
    else:
        print(f'  âœ… STABLE: Consistent performance across folds')

    # è¿‡æ‹Ÿåˆæ£€æŸ¥
    perfect_count = sum(1 for auc in cv_results if auc >= 0.99)
    print(f'\nğŸ” Overfitting Check:')
    print(f'  Folds with AUC â‰¥ 0.99: {perfect_count}/{len(cv_results)}')

    if perfect_count > 0:
        print(f'  âš ï¸  WARNING: {perfect_count} fold(s) show signs of severe overfitting')
        print(f'     Consider: smaller model, more regularization, more data')
    else:
        print(f'  âœ… No signs of severe overfitting')

    # ä¸´åºŠå¯ç”¨æ€§è¯„ä¼°
    print(f'\nğŸ¥ Clinical Viability:')
    clinical_threshold = 0.8
    clinical_folds = sum(1 for auc in cv_results if auc >= clinical_threshold)

    if mean_auc >= clinical_threshold and std_auc < 0.1:
        print(f'  âœ… CLINICALLY VIABLE: High performance with low variance')
    elif mean_auc >= clinical_threshold:
        print(f'  âš ï¸  PROMISING BUT UNSTABLE: Good average but high variance')
    else:
        print(f'  âŒ NOT READY: Performance below clinical threshold')

    print(f'  Folds meeting clinical threshold (â‰¥{clinical_threshold}): {clinical_folds}/{len(cv_results)}')

    # å»ºè®®
    print(f'\nğŸ’¡ Recommendations:')
    if perfect_count > 0:
        print(f'  1. ğŸ”§ Reduce model complexity (smaller network, more dropout)')
        print(f'  2. ğŸ“Š Check for data leakage between train/val sets')
        print(f'  3. ğŸ¯ Increase regularization (weight decay, early stopping)')

    if std_auc > 0.15:
        print(f'  4. ğŸ“ˆ Collect more data to improve stability')
        print(f'  5. ğŸ”„ Use ensemble methods to reduce variance')

    if mean_auc < clinical_threshold:
        print(f'  6. ğŸ¨ Try different architectures or pre-trained models')
        print(f'  7. ğŸ” Analyze misclassified cases for insights')

    # ç»˜åˆ¶ç»¼åˆåˆ†æå›¾
    plot_comprehensive_analysis(cv_results, detailed_results)


def plot_comprehensive_analysis(cv_results, detailed_results):
    """ç»˜åˆ¶ç»¼åˆåˆ†æå›¾è¡¨"""

    if not cv_results:
        return

    fig, axes = plt.subplots(2, 3, figsize=(18, 10))

    # 1. å„fold AUCå¯¹æ¯”
    axes[0, 0].bar(range(1, len(cv_results) + 1), cv_results,
                   color=['red' if auc >= 0.99 else 'orange' if auc >= 0.8 else 'lightcoral'
                          for auc in cv_results], alpha=0.7)
    axes[0, 0].axhline(y=0.8, color='green', linestyle='--', alpha=0.7, label='Clinical Threshold')
    axes[0, 0].axhline(y=0.99, color='red', linestyle='--', alpha=0.7, label='Overfitting Alert')
    axes[0, 0].set_xlabel('Fold')
    axes[0, 0].set_ylabel('AUC')
    axes[0, 0].set_title('AUC by Fold')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)

    # 2. AUCåˆ†å¸ƒç›´æ–¹å›¾
    axes[0, 1].hist(cv_results, bins=min(10, len(cv_results)),
                    color='skyblue', alpha=0.7, edgecolor='black')
    axes[0, 1].axvline(x=np.mean(cv_results), color='red', linestyle='--',
                       label=f'Mean: {np.mean(cv_results):.3f}')
    axes[0, 1].axvline(x=0.8, color='green', linestyle='--', alpha=0.7, label='Clinical')
    axes[0, 1].set_xlabel('AUC')
    axes[0, 1].set_ylabel('Frequency')
    axes[0, 1].set_title('AUC Distribution')
    axes[0, 1].legend()

    # 3. è¿‡æ‹Ÿåˆåˆ†æ
    if detailed_results:
        overfitting_gaps = [r['overfitting_gap'] for r in detailed_results]
        axes[0, 2].bar(range(1, len(overfitting_gaps) + 1), overfitting_gaps,
                       color=['red' if gap > 0.2 else 'orange' if gap > 0.1 else 'green'
                              for gap in overfitting_gaps], alpha=0.7)
        axes[0, 2].axhline(y=0.1, color='orange', linestyle='--', alpha=0.7, label='Warning')
        axes[0, 2].axhline(y=0.2, color='red', linestyle='--', alpha=0.7, label='Danger')
        axes[0, 2].set_xlabel('Fold')
        axes[0, 2].set_ylabel('Overfitting Gap')
        axes[0, 2].set_title('Overfitting Analysis')
        axes[0, 2].legend()
        axes[0, 2].grid(True, alpha=0.3)

    # 4. ç¨³å®šæ€§åˆ†æ
    axes[1, 0].boxplot(cv_results, labels=['AUC'])
    axes[1, 0].axhline(y=0.8, color='green', linestyle='--', alpha=0.7)
    axes[1, 0].set_ylabel('AUC')
    axes[1, 0].set_title('AUC Stability (Boxplot)')
    axes[1, 0].grid(True, alpha=0.3)

    # 5. æ•°æ®é›†å¤§å°vsæ€§èƒ½
    if detailed_results:
        train_sizes = [r['train_size'] for r in detailed_results]
        axes[1, 1].scatter(train_sizes, cv_results,
                           c=['red' if auc >= 0.99 else 'blue' for auc in cv_results],
                           alpha=0.7, s=100)
        axes[1, 1].set_xlabel('Training Set Size (patches)')
        axes[1, 1].set_ylabel('AUC')
        axes[1, 1].set_title('Dataset Size vs Performance')
        axes[1, 1].grid(True, alpha=0.3)

    # 6. æ€»ç»“ç»Ÿè®¡
    axes[1, 2].axis('off')

    mean_auc = np.mean(cv_results)
    std_auc = np.std(cv_results)
    perfect_count = sum(1 for auc in cv_results if auc >= 0.99)
    clinical_count = sum(1 for auc in cv_results if auc >= 0.8)

    summary_text = f"""
ğŸ“Š SUMMARY STATISTICS

Performance:
â€¢ Mean AUC: {mean_auc:.4f}
â€¢ Std AUC: {std_auc:.4f}
â€¢ Range: {min(cv_results):.4f} - {max(cv_results):.4f}

Stability:
â€¢ CV: {(std_auc / mean_auc) * 100:.1f}%
â€¢ {'âœ… Stable' if std_auc < 0.1 else 'âš ï¸ Unstable'}

Clinical Viability:
â€¢ Folds â‰¥ 0.80: {clinical_count}/{len(cv_results)}
â€¢ {'âœ… Ready' if clinical_count >= 4 else 'âŒ Not Ready'}

Overfitting:
â€¢ Perfect AUC: {perfect_count}/{len(cv_results)}
â€¢ {'âš ï¸ Suspected' if perfect_count > 0 else 'âœ… None detected'}
    """

    axes[1, 2].text(0.05, 0.5, summary_text, fontsize=12,
                    verticalalignment='center', fontfamily='monospace',
                    bbox=dict(boxstyle="round,pad=0.5", facecolor="lightblue", alpha=0.8))

    plt.suptitle('Comprehensive Model Diagnostic Report', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.savefig('comprehensive_diagnostic_report.png', dpi=150, bbox_inches='tight')
    plt.show()


def main():
    """ä¸»å‡½æ•° - è¯Šæ–­ç‰ˆæœ¬"""

    print("ğŸ” å¯åŠ¨ç—…ç†å›¾åƒåˆ†ç±»è¯Šæ–­ç³»ç»Ÿ")
    print("=" * 60)

    # æ•°æ®è·¯å¾„è®¾ç½®
    data_dir = './Data'  # è¯·ä¿®æ”¹ä¸ºå®é™…è·¯å¾„

    print("ğŸ“ åŠ è½½æ•°æ®ä¸­...")

    # æ”¶é›†å›¾åƒè·¯å¾„å’Œæ ‡ç­¾
    lnm_dir = os.path.join(data_dir, 'LNM')
    non_lnm_dir = os.path.join(data_dir, 'NOT-LNM')

    image_paths = []
    labels = []

    # LNMå›¾åƒ
    if os.path.exists(lnm_dir):
        for img_file in sorted(os.listdir(lnm_dir)):  # æ’åºç¡®ä¿ä¸€è‡´æ€§
            if img_file.lower().endswith(('.jpg', '.jpeg', '.png', '.tiff', '.tif')):
                image_paths.append(os.path.join(lnm_dir, img_file))
                labels.append(1)

    # non-LNMå›¾åƒ
    if os.path.exists(non_lnm_dir):
        for img_file in sorted(os.listdir(non_lnm_dir)):  # æ’åºç¡®ä¿ä¸€è‡´æ€§
            if img_file.lower().endswith(('.jpg', '.jpeg', '.png', '.tiff', '.tif')):
                image_paths.append(os.path.join(non_lnm_dir, img_file))
                labels.append(0)

    print(f'ğŸ“Š æ•°æ®é›†æ¦‚è§ˆ:')
    print(f'  æ€»å›¾åƒæ•°: {len(image_paths)}')
    print(f'  LNM: {sum(labels)}')
    print(f'  non-LNM: {len(labels) - sum(labels)}')
    print(f'  ç±»åˆ«æ¯”ä¾‹: {sum(labels) / len(labels):.3f} (LNM)')

    if len(image_paths) == 0:
        print("âŒ æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶!")
        print("   è¯·æ£€æŸ¥æ•°æ®ç›®å½•è·¯å¾„è®¾ç½®")
        return

    if len(set(labels)) < 2:
        print("âŒ åªæ‰¾åˆ°ä¸€ä¸ªç±»åˆ«çš„æ•°æ®!")
        print("   è¯·ç¡®ä¿LNMå’Œnon-LNMæ–‡ä»¶å¤¹éƒ½åŒ…å«å›¾åƒ")
        return

    # æ•°æ®è´¨é‡æ£€æŸ¥
    print(f'\nğŸ” æ•°æ®è´¨é‡æ£€æŸ¥:')

    # æ£€æŸ¥å›¾åƒæ–‡ä»¶å®Œæ•´æ€§
    valid_paths = []
    valid_labels = []

    for path, label in zip(image_paths, labels):
        try:
            img = cv2.imread(path)
            if img is not None:
                valid_paths.append(path)
                valid_labels.append(label)
            else:
                print(f"  âš ï¸  æ— æ³•è¯»å–: {os.path.basename(path)}")
        except Exception as e:
            print(f"  âŒ é”™è¯¯æ–‡ä»¶: {os.path.basename(path)} - {e}")

    image_paths = valid_paths
    labels = valid_labels

    print(f'  æœ‰æ•ˆå›¾åƒ: {len(image_paths)}/{len(image_paths)}')

    if len(image_paths) < 10:
        print("âš ï¸  è­¦å‘Š: å›¾åƒæ•°é‡å¤ªå°‘ï¼Œå¯èƒ½å½±å“äº¤å‰éªŒè¯ç»“æœ")

    # æ‰§è¡Œè¯Šæ–­æ€§äº¤å‰éªŒè¯
    print(f'\nğŸ”„ å¯åŠ¨è¯Šæ–­æ€§5æŠ˜äº¤å‰éªŒè¯...')
    print(f'âš™ï¸  é…ç½®: ä¿å®ˆæ¨¡å‹ + å¼ºæ­£åˆ™åŒ– + æ•°æ®æ³„æ¼æ£€æµ‹')

    cv_results, detailed_results = diagnostic_cross_validate(image_paths, labels, n_splits=5)

    # ç”Ÿæˆæœ€ç»ˆè¯Šæ–­æŠ¥å‘Š
    final_diagnostic_report(cv_results, detailed_results)

    print(f'\nâœ… è¯Šæ–­å®Œæˆ! è¯·æŸ¥çœ‹ç”Ÿæˆçš„å›¾è¡¨å’ŒæŠ¥å‘Šã€‚')

    # ç»™å‡ºå…·ä½“å»ºè®®
    if cv_results:
        mean_auc = np.mean(cv_results)
        std_auc = np.std(cv_results)
        perfect_count = sum(1 for auc in cv_results if auc >= 0.99)

        print(f'\nğŸ’¡ é’ˆå¯¹æ‚¨å½“å‰ç»“æœçš„å…·ä½“å»ºè®®:')

        if perfect_count > 0:
            print(f'  ğŸš¨ ç´§æ€¥: {perfect_count}ä¸ªfoldå‡ºç°å®Œç¾AUCï¼Œå¼ºçƒˆå»ºè®®:')
            print(f'     - æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®æ³„æ¼')
            print(f'     - å‡å°‘modelå¤æ‚åº¦')
            print(f'     - å¢å¼ºæ­£åˆ™åŒ–')

        if std_auc > 0.15:
            print(f'  ğŸ“Š ç¨³å®šæ€§å·®ï¼Œå»ºè®®:')
            print(f'     - æ”¶é›†æ›´å¤šæ•°æ®')
            print(f'     - ä½¿ç”¨ensembleæ–¹æ³•')

        if mean_auc < 0.8:
            print(f'  ğŸ“ˆ æ€§èƒ½å¾…æå‡ï¼Œå»ºè®®:')
            print(f'     - å°è¯•ä¸åŒçš„é¢„è®­ç»ƒæ¨¡å‹')
            print(f'     - è°ƒæ•´æ•°æ®å¢å¼ºç­–ç•¥')
            print(f'     - åˆ†æé”™è¯¯åˆ†ç±»æ¡ˆä¾‹')


if __name__ == '__main__':
    main()